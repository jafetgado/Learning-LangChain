{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 - RAG Part I: Indexing Your Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import uuid \n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader, WebBaseLoader, PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, Language\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_core.documents import Document\n",
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "from ragatouille import RAGPretrainedModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI API from .env file\n",
    "api_openai = load_dotenv(dotenv_path='./api.env')\n",
    "api_openai = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting documents to text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generally, to load a document with LangChain\n",
    "\n",
    "    1. Select the loader for your document type\n",
    "    \n",
    "    2. Create an instance of the loader, specifying configuration parameters\n",
    "    \n",
    "    3. Load the documents by calling `.load()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1\n",
      "dict_keys(['id', 'metadata', 'page_content', 'type'])\n"
     ]
    }
   ],
   "source": [
    "# Loading a text document\n",
    "loader = TextLoader('data/test.txt', encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "\n",
    "# View doc\n",
    "print(type(docs)) # List\n",
    "print(len(docs)) # 1 item\n",
    "print(docs[0].model_dump().keys()) # View keys of loaded document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1\n",
      "dict_keys(['id', 'metadata', 'page_content', 'type'])\n"
     ]
    }
   ],
   "source": [
    "# Loading text from a web URL\n",
    "loader = WebBaseLoader('https://www.langchain.com/')\n",
    "docs = loader.load()\n",
    "\n",
    "# View doc\n",
    "print(type(docs)) # List\n",
    "print(len(docs)) # 1 item\n",
    "print(docs[0].model_dump().keys()) # View keys of loaded document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1\n",
      "dict_keys(['id', 'metadata', 'page_content', 'type'])\n"
     ]
    }
   ],
   "source": [
    "# Loading text from a PDF file\n",
    "loader = PyPDFLoader('data/test.pdf') # install the pdf parsing library !pip install pypdf\n",
    "docs = loader.load()\n",
    "\n",
    "# View doc\n",
    "print(type(docs)) # List\n",
    "print(len(docs)) # 1 item\n",
    "print(docs[0].model_dump().keys()) # View keys of loaded document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunking: Split your text into chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The retrieved document may be very large, beyond the context size of the LLM.\n",
    "\n",
    "* You need to split the document into semantically related chunks\n",
    "\n",
    "* LangChain provides RecursiveCharacterTextSplitter to do this. It works as follows:\n",
    "\n",
    "    1. Take a list of separators: word, line, and paragraph separators (' ', '\\n', \\n\\n', respectively)\n",
    "\n",
    "    2. Start by splitting up the paragraphs (largest chunks)\n",
    "\n",
    "    3. For any chunk (paragraph) larger than the specified chunk size (e.g. 1000 characters), split by the next separator (lines). Do this until all chunks are smaller than the desired length, or there are no separators to try.\n",
    "\n",
    "    4. Chunks are generated with overlap. E.g., if chunk_overlap is 200, the second chunk begins 200 characters before the end of the previous chunk. This is done to preserve important context (especially at chunk boundaries).\n",
    "    \n",
    "    5. Return each chunk as a document, with the metadata of the original document, and information about the position in the original document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624212\n",
      "864\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Chunking a document\n",
    "\n",
    "# First load the document\n",
    "loader = TextLoader('data/test.txt', encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "print(len(docs[0].page_content)) # 624,212 characters\n",
    "\n",
    "# Now chunk the document\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "sdocs = splitter.split_documents(docs)\n",
    "print(len(sdocs)) # 864 chunks\n",
    "\n",
    "# Visualize number of characters in chunks\n",
    "sizes = [len(item.page_content) for item in sdocs]\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.hist(sizes);\n",
    "plt.xlabel('No. of characters in chunk');\n",
    "plt.ylabel('Frequency');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[Document(metadata={}, page_content='def hello_world(): print(\"Hello, World!\") # Call'), Document(metadata={}, page_content='the function hello_world()')]\n",
      "dict_keys(['id', 'metadata', 'page_content', 'type'])\n"
     ]
    }
   ],
   "source": [
    "# Chunking a document with code by using Language\n",
    "# Create a specific instance of RecursiveCharacterTextSplitter for the specific language (python)\n",
    "PYTHON_CODE = \"\"\" def hello_world(): print(\"Hello, World!\") # Call the function hello_world() \"\"\"\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, \n",
    "    chunk_size=50, \n",
    "    chunk_overlap=0\n",
    ")\n",
    "pdocs = python_splitter.create_documents([PYTHON_CODE])\n",
    "print(len(pdocs))\n",
    "print(pdocs)\n",
    "print(pdocs[0].model_dump().keys()) # Note that the documents lack metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://www.langchain.com'}, page_content='# ü¶úüîó LangChain ‚ö° Building applications with LLMs through'), Document(metadata={'source': 'https://www.langchain.com'}, page_content='composability'), Document(metadata={'source': 'https://www.langchain.com'}, page_content='‚ö° ## Quick Install'), Document(metadata={'source': 'https://www.langchain.com'}, page_content='```\\nbash pip install langchain \\n```'), Document(metadata={'source': 'https://www.langchain.com'}, page_content='As an open source project in a rapidly developing field, we'), Document(metadata={'source': 'https://www.langchain.com'}, page_content='are extremely open'), Document(metadata={'source': 'https://www.langchain.com'}, page_content='to contributions.')]\n"
     ]
    }
   ],
   "source": [
    "# Splitting text in markdown and supplying metadata as an argument\n",
    "markdown_text = \"\"\" \n",
    "# ü¶úüîó LangChain ‚ö° Building applications with LLMs through composability \n",
    "‚ö° ## Quick Install \n",
    "```\n",
    "bash pip install langchain \n",
    "``` \n",
    "As an open source project in a rapidly developing field, we are extremely open     \n",
    "to contributions.\n",
    "\"\"\"\n",
    "md_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN, chunk_size=60, chunk_overlap=0\n",
    ")\n",
    "\n",
    "md_docs = md_splitter.create_documents(\n",
    "    [markdown_text], \n",
    "    [{\"source\": \"https://www.langchain.com\"}] # Specify metadata\n",
    "    )\n",
    "print(md_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating text embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* OpenAI provides two strong embedding models: `text-embedding-3-small` and `text-embedding-3-large`, with 1536 and 3072 dimensions, respectively ([see link](https://platform.openai.com/docs/guides/embeddings/embedding-models)).\n",
    "\n",
    "* While the training procedure and architecture of these models aren't public, they likely follow the same training process as the popular embedding model, all-MiniLM-L6-v2 in sentence-transformers, i.e. contrastive loss on sentence pairs ([see link for more details](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "(5, 1536)\n",
      "[[-0.01918744 -0.03813097 -0.03100343 ... -0.01432283  0.00739177\n",
      "   0.01708712]\n",
      " [ 0.00824871 -0.0246296  -0.0780101  ... -0.01674273 -0.00386984\n",
      "  -0.00571583]\n",
      " [ 0.02240088 -0.01531259 -0.03209254 ... -0.01715862 -0.00572743\n",
      "   0.00867398]\n",
      " [ 0.03665848 -0.05241179 -0.00481682 ... -0.01532152 -0.0068381\n",
      "   0.03442502]\n",
      " [-0.00301562 -0.05678004  0.02944902 ... -0.0095528   0.00158941\n",
      "  -0.00038307]]\n"
     ]
    }
   ],
   "source": [
    "# Embedding documents (a list of strings)\n",
    "model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "embeddings = model.embed_documents([\n",
    "    \"Hi there!\",\n",
    "    \"Oh, hello!\",\n",
    "    \"What's your name?\",\n",
    "    \"My friends call me World\",\n",
    "    \"Hello World!\"\n",
    "]) \n",
    "print(type(embeddings)) # returns a list\n",
    "embeddings = np.asarray(embeddings)\n",
    "print(embeddings.shape)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864, 1536)\n"
     ]
    }
   ],
   "source": [
    "# Split and embed text in test.txt\n",
    "\n",
    "# First, load the document\n",
    "loader = TextLoader(\"data/test.txt\", encoding=\"utf-8\")\n",
    "doc = loader.load()\n",
    "\n",
    "# Split the document\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(doc)\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "    [chunk.page_content for chunk in chunks]\n",
    ")\n",
    "print(np.array(embeddings).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing embeddings in a vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PGVector is an extension that enables you to use a very popular open source relational database (PostgreSQL) as a vector store for embeddings.\n",
    "\n",
    "* To use PGVector, ensure that docker is setup for your OS ([see link](https://oreil.ly/Gn28O)).\n",
    "\n",
    "* We use docker to run PostgreSQL for\n",
    "    1. Isolation: avoid polluing host system with database files and binaries.\n",
    "\n",
    "    2. Portbility: you can run the same setup across different machines or environments\n",
    "\n",
    "    3. Easy setup and cleanup: easy to build a containerized database and to cleanup/remove the container after use\n",
    "\n",
    "    4. Version control: Can easily specify exact version of postgreSQL and extensions, with minimal conflicts\n",
    "    \n",
    "    5. Multiple instances: can run multiple versions and configurations without interference.\n",
    "\n",
    "\n",
    "* Start the postgreSQL container by running the following in shell:\n",
    "\n",
    "```\n",
    "docker run \\\n",
    "    --name pgvector-container \\\n",
    "    -e POSTGRES_USER=langchain \\\n",
    "    -e POSTGRES_PASSWORD=langchain \\\n",
    "    -e POSTGRES_DB=langchain \\\n",
    "    -p 6024:5432 \\\n",
    "    -d pgvector/pgvector:pg16\n",
    "```    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what each part of the docker command does:\n",
    "\n",
    "*docker run*\n",
    "\n",
    "* Starts a new Docker container.\n",
    "\n",
    "*--name pgvector-container*\n",
    "\n",
    "* Names the container pgvector-container.\n",
    "\n",
    "*-e POSTGRES_USER=langchain \\ *\n",
    "*-e POSTGRES_PASSWORD=langchain \\ *\n",
    "*-e POSTGRES_DB=langchain \\ *\n",
    "\n",
    "* Sets environment variables inside the container to create a database named langchain, create a user langchain with password langchain. These are required for initializing PostgreSQL.\n",
    "\n",
    "*-p 6024:5432*\n",
    "\n",
    "* Maps port 5432 in the container (default PostgreSQL port) to port 6024 on your machine. You can connect to the database locally at localhost:6024.\n",
    "\n",
    "\n",
    "*-d pgvector/pgvector:pg16*\n",
    "\n",
    "* Runs the container in detached mode (-d), meaning it runs in the background. Uses the Docker image pgvector/pgvector:pg16, which is PostgreSQL 16 with the pgvector extension pre-installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create vector store for chunked documents with embeddings\n",
    "\n",
    "# First, Connection for postgresql running in docker (see shell command)\n",
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "\n",
    "# Load the document, split it into chunks\n",
    "raw_documents = TextLoader('data/test.txt', encoding=\"utf-8\").load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "# Create embeddings for the documents and store in a postgresql database using the pgvector extension\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "db = PGVector.from_documents(documents, embeddings_model, connection=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "4\n",
      "\n",
      "page_content='Chapter 1: Life in Ancient Greece\n",
      "Life in ancient Greece was a tapestry woven with rich cultural, social, and political threads that have left an enduring legacy on Western civilization. Centered around the polis, or city-state, ancient Greek society fostered a unique blend of communal living, intellectual pursuit, and artistic innovation. This chapter delves into the multifaceted aspects of daily life in ancient Greece, exploring the social structure, education, religion, economy, and contributions to art and architecture that defined this remarkable civilization.\n",
      "The Polis: Heart of Greek Society' metadata={'source': 'data/test.txt'}\n",
      "\n",
      "page_content='---\n",
      "This chapter provides a comprehensive overview of life in ancient Greece, setting the stage for a detailed exploration of its enduring contributions to the world. Through understanding the intricate dynamics of the polis, the pursuit of education and intellectual growth, the depth of religious practices, and the brilliance in art and engineering, we can better appreciate the sophistication and resilience of ancient Greek civilization.' metadata={'source': 'data/test.txt'}\n",
      "\n",
      "page_content='Gender Roles and Family Life\n",
      "While male citizens engaged in public life, women primarily managed household affairs and took care of children. However, the roles and freedoms of women varied significantly between city-states. In Athens, women's public presence was limited, whereas in Sparta, women enjoyed greater autonomy and could own property, reflecting the militaristic and pragmatic nature of Spartan society.\n",
      "Education and Intellectual Pursuits\n",
      "Education was a cornerstone of Greek society, especially in Athens, where citizens were encouraged to pursue knowledge and develop critical thinking skills. Young boys attended schools to study subjects such as reading, writing, mathematics, music, and physical education. The gymnasium played a central role, serving not only as a place for athletic training but also as a hub for intellectual discussions and philosophical debates.\n",
      "The Gymnasium: A Nexus of Body and Mind' metadata={'source': 'data/test.txt'}\n",
      "\n",
      "page_content='Economy and Trade\n",
      "Ancient Greece's economy was vibrant and diverse, driven by agriculture, craftsmanship, and extensive trade networks. The fertile plains supported the cultivation of olives, grapes, and grains, which were staples of the Greek diet and essential for trade.\n",
      "The Agora: Marketplace and Social Hub\n",
      "The agora was the bustling marketplace and central meeting place in each polis. Here, merchants sold goods ranging from fresh produce and seafood to handcrafted pottery and textiles. The agora was not only a center for economic activity but also a venue for social interaction, political discussion, and the exchange of ideas.\n",
      "Maritime Trade and Colonization' metadata={'source': 'data/test.txt'}\n"
     ]
    }
   ],
   "source": [
    "# Do similarity search to retrieve relevant documents\n",
    "results = db.similarity_search(\"What was life in ancient greece like?\", k=4)\n",
    "print(type(results)) # List of 4 documents retrieved with greatest similarity\n",
    "print(len(results))\n",
    "for item in results:\n",
    "    print()\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that pgvector uses exact search for the retrieval/similarity search, not an approximate neighbor algorithm (ANN). To specify an ANN, which may be necessary for large databases, you need to specify the ANN with an SQL command to create the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding documents to the vector store\n",
      "Documents added successfully.\n",
      " Fetched documents count: 2\n"
     ]
    }
   ],
   "source": [
    "# Adding documents to the existing database\n",
    "print(\"Adding documents to the vector store\")\n",
    "ids = [str(uuid.uuid4()), str(uuid.uuid4())] # Create two document ids with python's uuid library\n",
    "db.add_documents(\n",
    "    [\n",
    "        Document(\n",
    "            page_content=\"there are cats in the pond\",\n",
    "            metadata={\"location\": \"pond\", \"topic\": \"animals\"},\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"ducks are also found in the pond\",\n",
    "            metadata={\"location\": \"pond\", \"topic\": \"animals\"},\n",
    "        ),\n",
    "    ],\n",
    "    ids=ids,\n",
    ")\n",
    "\n",
    "print(\"Documents added successfully.\\n Fetched documents count:\",\n",
    "      len(db.get_by_ids(ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting document with id fac86026-3e79-4669-b25c-cba2dd773289\n"
     ]
    }
   ],
   "source": [
    "# Deleting document from database\n",
    "print(\"Deleting document with id\", ids[1])\n",
    "db.delete({\"ids\": [ids[1]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking changes to your documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If the documents change (e.g. addition of text files), you'll need to reindex them, but this is computationally costly or leads to duplications of existing content.\n",
    "\n",
    "* LangChanin provides an indexing API to make it easy to keep documents in sync with the vector store. This API uses the `RecordManager` class.\n",
    "\n",
    "* The indexing API also provides cleanup modes to help you decide how to delete existing documents in the vector store. The modes are:\n",
    "\n",
    "    1. None mode: Always re-adds all documents without tracking duplicates or changes. Don't do any automatic cleanup, user manually cleans up old content. \n",
    "\n",
    "    2. Incremental mode: Adds only new documents by ID, ignoring content changes.\n",
    "    \n",
    "    3. Full mode: Adds new documents and updates existing ones if their content has changed, using ID and content hash tracking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index attempt 1: {'num_added': 2, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}\n",
      "Index attempt 2: {'num_added': 0, 'num_updated': 0, 'num_skipped': 2, 'num_deleted': 0}\n",
      "Index attempt 3: {'num_added': 1, 'num_updated': 0, 'num_skipped': 1, 'num_deleted': 1}\n"
     ]
    }
   ],
   "source": [
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "collection_name = \"my_docs\"\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "namespace = \"my_docs_namespace\"\n",
    "\n",
    "# Create vector store from database\n",
    "vectorstore = PGVector(\n",
    "    embeddings=embeddings_model,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")\n",
    "\n",
    "# Initialize record manager with database\n",
    "record_manager = SQLRecordManager(\n",
    "    namespace,\n",
    "    db_url=\"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\",\n",
    ")\n",
    "record_manager.create_schema()  # Create the schema if it doesn't exist\n",
    "\n",
    "# Create new documents\n",
    "docs = [\n",
    "    Document(page_content='there are cats in the pond', metadata={\n",
    "             \"id\": 1, \"source\": \"cats.txt\"}),\n",
    "    Document(page_content='ducks are also found in the pond', metadata={\n",
    "             \"id\": 2, \"source\": \"ducks.txt\"}),\n",
    "]\n",
    "\n",
    "# Index the documents with the record manager\n",
    "index_1 = index(\n",
    "    docs,\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",  # prevent duplicate documents, add only new documents, but don't deal with changes to old ones.\n",
    "    source_id_key=\"source\",  # use the source field as the source_id\n",
    ")\n",
    "print(\"Index attempt 1:\", index_1)\n",
    "\n",
    "# Attempt to index the documents again, it will not add the documents again\n",
    "index_2 = index(\n",
    "    docs,\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")\n",
    "print(\"Index attempt 2:\", index_2)\n",
    "\n",
    "# If we mutate a document, the new version will be written and all old versions sharing the same source will be deleted.\n",
    "docs[0].page_content = \"I just modified this document!\"\n",
    "index_3 = index(\n",
    "    docs,\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")\n",
    "print(\"Index attempt 3:\", index_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiVectorRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiVectorRetriever is a retriever in LangChain designed to improve information retrieval by using multiple vectors per document rather than a single embedding. This helps capture different aspects of a document and improves recall and relevance when querying.\n",
    "\n",
    "Why use it?\n",
    "* Standard retrieval typically generates one embedding per document or chunk. But documents can contain multiple ideas. \n",
    "\n",
    "* MultiVectorRetriever lets you represent a document with multiple sub-embeddings, each corresponding to a different perspective, topic, or summary.\n",
    "\n",
    "How it works\n",
    "* A description function generates multiple \"descriptions\" or summaries per document. These are called representations.\n",
    "\n",
    "* Each description is embedded separately, so each document gets multiple embeddings.\n",
    "\n",
    "* During retrieval, your query is embedded and compared to all representations across all documents.\n",
    "\n",
    "* Matches are returned with reference to the original document.\n",
    "\n",
    "Benefits\n",
    "* Improves semantic recall by allowing different parts of the document to match a query.\n",
    "\n",
    "* Especially helpful for long documents or documents with multiple topics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of loaded docs:  624212\n",
      "sub docs:  Chapter I discusses the early Greek thought, highlighting the strength and universality of the Greek intellect, the specialization of individual genius, the sense of harmony and union, and the circumstances that shaped the intellectual character of the Greeks. It also mentions how philosophy was a natural product of the Greek mind, with speculation initially focused on the external world. The chapter emphasizes the important results achieved by early Greek thinkers and how their conception of a cosmos laid the foundation for science. Additionally, it disproves the alleged influence of Oriental ideas on early Greek thought.\n",
      "length of sub docs:\n",
      " 630\n",
      "length of retrieved docs:  538\n"
     ]
    }
   ],
   "source": [
    "# MultiVectorRetreival example\n",
    "\n",
    "# PGVector Connection and model\n",
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "collection_name = \"summaries\"\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "# Load the document\n",
    "loader = TextLoader(\"data/test.txt\", encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "print(\"length of loaded docs: \", len(docs[0].page_content))\n",
    "\n",
    "# Split the document\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# Generate summary for document\n",
    "prompt_text = \"Summarize the following document:\\n\\n{doc}\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "summarize_chain = {\n",
    "    \"doc\": lambda x: x.page_content} | prompt | llm | StrOutputParser()\n",
    "\n",
    "# Batch the summary chain across the chunks\n",
    "summaries = summarize_chain.batch(chunks, {\"max_concurrency\": 5})\n",
    "\n",
    "# Initialize the vectorstore to use to index the child chunks\n",
    "vectorstore = PGVector(\n",
    "    embeddings=embeddings_model,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# Indexing the summaries in our vector store, whilst retaining the original documents in our document store:\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "# Changed from summaries to chunks since we need same length as docs\n",
    "doc_ids = [str(uuid.uuid4()) for _ in chunks]\n",
    "\n",
    "# Each summary is linked to the original document by the doc_id\n",
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]\n",
    "\n",
    "# Add the document summaries to the vector store for similarity search\n",
    "retriever.vectorstore.add_documents(summary_docs)\n",
    "\n",
    "# Store the original documents in the document store, linked to their summaries via doc_ids\n",
    "# This allows us to first search summaries efficiently, then fetch the full docs when needed\n",
    "retriever.docstore.mset(list(zip(doc_ids, chunks)))\n",
    "\n",
    "# Vector store retrieves the summaries\n",
    "sub_docs = retriever.vectorstore.similarity_search(\n",
    "    \"chapter on philosophy\", k=2)\n",
    "print(\"sub docs: \", sub_docs[0].page_content)\n",
    "print(\"length of sub docs:\\n\", len(sub_docs[0].page_content))\n",
    "\n",
    "# Whereas the retriever will return the larger source document chunks:\n",
    "retrieved_docs = retriever.invoke(\"chapter on philosophy\")\n",
    "print(\"length of retrieved docs: \", len(retrieved_docs[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ColBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ColBERT (Contextualized Late Interaction over BERT) is a dense retrieval model designed to efficiently and accurately search large document collections using late interaction between token-level embeddings. It's often used in neural information retrieval and RAG pipelines to improve search quality while maintaining scalability.\n",
    "\n",
    "* Core Idea: Traditional dense retrievers encode queries and documents into single vectors and compute similarity via dot product or cosine similarity. \n",
    "\n",
    "* ColBERT differs by:\n",
    "\n",
    "    - Encoding queries and documents as sets of token embeddings, not a single vector.\n",
    "\n",
    "    - Computing similarity via fine-grained token-level interactions (using maximum or sum of dot products between token embeddings).\n",
    "\n",
    "* This allows ColBERT to capture more nuanced matching patterns while keeping the retrieval scalable using Approximate Nearest Neighbor (ANN) indexing.\n",
    "\n",
    "* Architecture: Base encoder: Typically BERT or RoBERTa.\n",
    "\n",
    "* Late interaction: After encoding, document and query tokens are not immediately combined (averaged). Instead, similarities are computed after indexing (hence ‚Äúlate‚Äù).\n",
    "\n",
    "* Scoring function: Uses MaxSim, which for each query token finds the maximum similarity with any document token and then sums these.\n",
    "\n",
    "* Usage in RAG: ColBERT is used to:\n",
    "\n",
    "    - Replace traditional retrievers in RAG pipelines.\n",
    "\n",
    "    - Improve semantic matching beyond single-vector encoders.\n",
    "\n",
    "    - Scale to large corpora using tools like Faiss or ColBERTv2's custom indexers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use RAGatouille to run ColBERT\n",
    "- Read full docs here: https://github.com/AnswerDotAI/RAGatouille/blob/8183aad64a9a6ba805d4066dcab489d97615d316/README.md\n",
    "- To install run:\n",
    "```bash\n",
    "pip install -U ragatouille transformers\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "\n",
    "\n",
    "def get_wikipedia_page(title: str):\n",
    "    \"\"\"\n",
    "    Retrieve the full text content of a Wikipedia page.\n",
    "    :param title: str - Title of the Wikipedia page.\n",
    "    :return: str - Full text content of the page as raw string.\n",
    "    \"\"\"\n",
    "    # Wikipedia API endpoint\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "    # Parameters for the API request\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": title,\n",
    "        \"prop\": \"extracts\",\n",
    "        \"explaintext\": True,\n",
    "    }\n",
    "    # Custom User-Agent header to comply with Wikipedia's best practices\n",
    "    headers = {\"User-Agent\": \"RAGatouille_tutorial/0.0.1\"}\n",
    "    response = requests.get(URL, params=params, headers=headers)\n",
    "    data = response.json()\n",
    "    # Extracting page content\n",
    "    page = next(iter(data[\"query\"][\"pages\"].values()))\n",
    "    return page[\"extract\"] if \"extract\" in page else None\n",
    "\n",
    "\n",
    "full_document = get_wikipedia_page(\"Hayao_Miyazaki\")\n",
    "# Create an index\n",
    "RAG.index(\n",
    "    collection=[full_document],\n",
    "    index_name=\"Miyazaki-123\",\n",
    "    max_document_length=180,\n",
    "    split_documents=True,\n",
    ")\n",
    "# query\n",
    "results = RAG.search(query=\"What animation studio did Miyazaki found?\", k=3)\n",
    "print(results)\n",
    "\n",
    "# Alternative: Utilize langchain retriever\n",
    "retriever = RAG.as_langchain_retriever(k=3)\n",
    "retriever.invoke(\"What animation studio did Miyazaki found?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
